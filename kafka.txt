kafka，  传kafka\zk\

https://www.cnblogs.com/shej123/p/10277653.html
5、使用idea在git 上下载kafka-monitor 代码，地址：https://github.com/linxin26/kafka-monitor

运行Start,在浏览器输入http://127.0.0.1:5050
一、概念
       1、是什么？   是一个分布式的 
                   基于发布/订阅模式的消息队列（MQ），
                   主要应用于大数据实时处理领域

       2、作用： 解耦 / 
          可恢复性（系统一部分组件失效时，不会影响整个系统）
          缓冲（解决生产消息和消费消息速度不一致）
          灵活性/ 峰值处理 ：  削峰
           异步
  
       ！注意：主要是    解耦和削峰


     3、消息队列的两种模式：
       1）、点对点模式（一对一） 
         消费者主动拉取数据，消息收到后消息清除
       2）、发布/订阅模式（一对多）
      消息生产者将消息发布导Topic中，同时多个消费者（订阅）消费该消息，并且消费完数据后，数据不会清除
        ①消费者主动拉取  （kafka属于这一种）：速度由消费者自身决定；当没消息时，会反复多次询问Topic
        ②公众号推送   ： 速度由推送者决定


    4.  kafka组成
 	1). 生产者生产消息：ProducerA 、ProducerB、
   	2). kafka集群管理消息：不同的主题、leader/Follower（备份）
   	3). 消费者消费消息：ConsumerA、ConsumerB、ConsumeC、
          同一个消费组的消费者不能消费同一个消费分区数据


       Broker：Kafka集群包含一个或多个服务器，这种服务器被称为broker。
　　Topic：每条发布到Kafka集群的消息都有一个主题名称，这个主题名称就被称为Topic。
　　Partition：Partition是物理上的概念，每个Topic包含一个或多个Partition。
　　Producer：消息生产者，负责发布消息到Kafka broker。
　　Consumer：消息消费者，向Kafka broker读取消息的客户端。
　　Consumer Group：每个Consumer属于一个特定的Consumer Group，group name可单独设定，若不设定则属于默认的group。

zookeeper？ 注册消息      0.9版本之后？？？

二、测试kafka:
          1. 启动命令（在kafka根目录下，前提是启动zk）
	.\bin\windows\kafka-server-start.bat .\config\server.properties

         2.  创建主题（Topic）命令,  xxxxx为自定义的topic名称
	.\bin\windows\kafka-topics.bat --create --zookeeper localhost:2181  --replication-factor 1 --partitions 2 --topic   xxxxx

        3. 查看主题命令
             //看所以主题
	.\bin\windows\kafka-topics.bat --list --zookeeper localhost:2181
            //看具体某个主题详情
	.\bin\windows\kafka-topics.bat --describe --zookeeper localhost:2181  --topic xxx

        4. 接受消息
	.\bin\windows\kafka-console-consumer.bat --bootstrap-server localhost:9092 --topic xxxx --from-beginning

        5.  发送消息
	.\bin\windows\kafka-console-producer.bat --broker-list localhost:9092 --topic xxx

三、java测试kafka：
     1.  依赖


   2.   生产者类： Producer

        3. 消费者类 ：Consumer



四、自定义拦截器

五、其他参数
      1. acks  ： 必须又多少个副本收到这条消息，生产者才认为成功
           acks = 0   生产者在成功写入消息之前不会等待任何来自服务器的响应
           acks=1  只要集群的首领节点收到消息，生产这就会收到一个来自服务器的成功响 应。如果消息无法达到首领节点（比如首领节点崩溃，新的首领还没有被选举出来），生产者会收 到一个错误响应，为了避免数据丢失，生产者会重发消息
          ack=-1， 只有当所有参与复制的节点都收到消息时，生产这会收到一个来自服务器的成功响应， 这种模式是最安全的，它可以保证不止一个服务器收到消息。

!!!!!!注意：acks参数配置的是一个字符串类型，而不是整数类型，如果配置为整数类型会抛出以下异常
      2. retries
	生产者从服务器收到的错误有可能是临时性的错误（比如分区找不到首领）。在这种	情况下，如果达到 了 retires 设置的次数，生产者会放弃重试并返回错误。默认情况	下，生产者会在每次重试之间等待 100ms，可以通过 retry.backoff.ms 参数来修改	这个时间间隔
           
     3.  batch.size 
	当有多个消息要被发送到同一个分区时，生产者会把它们放在同一个批次里。该参数	指定了一个批次可 以使用的内存大小，按照字节数计算，而不是消息个数。当批次	被填满，批次里的所有消息会被发送出 去。不过生产者并不一定都会等到批次被填	满才发送，半满的批次，甚至只包含一个消息的批次也可能 被发送。所以就算把 	batch.size 设置的很大，也不会造成延迟，只会占用更多的内存而已，如果设置 的	太小，生产者会因为频繁发送消息而增加一些额外的开销。

     4. max.request.size 
	该参数用于控制生产者发送的请求大小，它可以指定能发送的单个消息的最大值，也	可以指单个请求里 所有消息的总大小。 broker 对可接收的消息最大值也有自己的限	制（ message.max.size ），所以两 边的配置最好匹配，避免生产者发送的消息被 	broker 拒绝。 

六、位移提交（自动，同动，异步）
  	 默认自动
  	 手动提交开启
        		props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);
        		return props;
	异步。。。

七、指定位移消费
  seek()  :得以追踪以前的消息


八、主题管理(create\list\alter\alter_delete)
         1.   创建主题（Topic）命令,  xxxxx为自定义的topic名称
	.\bin\windows\kafka-topics.bat --create --zookeeper localhost:2181  --replication-factor 1 --partitions 2 --topic   xxxxx
               多个zk 用“，” 分开
	partitions ：设置主题分区数，每个线程处理一个分区数据
	replication-factor ：用于设置主题副本数，每个副本分布在不同节点，不能超过总节点数

        2.   查看主题命令
             （1）看所以主题
	.\bin\windows\kafka-topics.bat --list --zookeeper localhost:2181
             （2）看具体某个主题详情
	.\bin\windows\kafka-topics.bat --describe --zookeeper localhost:2181  --topic xxx

        3.   修改主题（增加配置 + 删除配置）
	增加配置:
	 .\bin\windows\kafka-topics.bat --alter -zookeeper localhost:2181 --topic heima --config flush.messages=1
	删除配置:
	.\bin\windows\kafka-topics.bat --alter -zookeeper localhost:2181 --topic heima --delete-config flush.messages 
                 【多了个delete】

          4. 删除主题
       	（1）若 delete.topic.enable=true  直接彻底删除该 Topic。 
	       .\bin\windows\kafka-topics.bat --delete -zookeeper localhost:2181 --topic heima

	（2）若 delete.topic.enable=false  如果当前 Topic 没有使用过即没有传输过信息：可以彻底删除				。  如果当前 Topic 有使用过即有过传输过信息： 并没有真正删除 Topic 只是把这个 				Topic 标	记为删除(marked for deletion)，重启 Kafka Server 后删 除。
             .\bin\windows\kafka-topics.bat --delete -zookeeper localhost:2181 --topic heima
	删除后可以通过查看主题，看到__consumer_offsets  ： 表示标记为删除，然后重启就删除成功了
              【关机命令】.\bin\windows\kafka-server-stop.bat
              【开机命令】.\bin\windows\kafka-server-start.bat .\config\server.properties

九、分区管理（partition）


        1. 增加分区：修改分区数时，只能增加分区数，不能减少分区数
              .\bin\windows\kafka-topics.bat --alter -zookeeper localhost:2181 --topic heima --partitions 3
        
	分区重新分配



十、kafka存储

十一、 稳定性
           1. 幂等性（类似可重复读）：对接口多次调用所产生的结果和调用一次是一致的（对同一接口的多次调用结果都一致）
            （1） 幂等性的局限：①只能保证提供者在单个会话内不丢不重
                                        ②幂等性不能跨多个Topic-partition,
            （2）使用：只需把Producer 的配置enable.idempotence设置成true即可（默认就为true）
                    不配置默认实现幂等性
         
            2. 事务（弥补幂等性的局限）：要么全部成功，要么全部失败
                （1）使用：需要将ProducerConﬁg.ENABLE_IDEMPOTENCE_CONFIG设置为true（默认值为true），
	①//初始化事务，前提是配置了transactionalId
	public void initTransactions()
	②//开启事务
	public void beginTransaction()
	③//为消费者提供事务内的位移提交操作
	public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata>
	offsets, String consumerGroupId)
	④//提交事务
	public void commitTransaction()
	⑤//终止事务，类似于回滚
	public void abortTransaction()

            3. 控制器   ：在Kafka集群中会有一个或者多个broker，其中有一个broker会被选举为控制器（Kafka 		Controller），
		它负责管理整个集群中所有分区和副本的状态。当某个分区的leader副本出现故障时，由控制器负			责为该分区选举新的leader副本。
            4. zk可视化工具   ZooInspector 
     
            5. 可靠性保证

十二、kafka高级应用
           1 . 消费组管理
	 （1）查看消费组
                  .\bin\windows\kafka-consumer-groups.bat --bootstrap-server 127.0.0.1:9092 --list

	 （2）查看消费组详情
	  .\bin\windows\kafka-consumer-groups.bat --bootstrap-server 127.0.0.1:9092 --describe --group xxx消费组名xxx

	 （3）查看消费组状态
	  .\bin\windows\kafka-consumer-groups.bat --bootstrap-server 127.0.0.1:9092 --describe --group xxx消费组名xxx --state

	 （4）查看消费组内成员
	  .\bin\windows\kafka-consumer-groups.bat --bootstrap-server 127.0.0.1:9092 --describe --group xxx消费组名xxx --members

	 （5）删除消费组，如果有消费者在使用则失败
	  .\bin\windows\kafka-consumer-groups.bat --bootstrap-server 127.0.0.1:9092 --delete --group xxx消费组名xxx

           2. 消费位移管理
	  .\bin\windows\kafka-consumer-groups.bat --bootstrap-server 127.0.0.1:9092  --group  xxx消费组名xxx  --all-topics --reset-offsets  --to-earliest --execute

           3. 数据管道Connect   (源 --kafka --目标)
                （1）配置连接 }/config/connect-file-sink.properties
        
                           【注意】修改  ①文件地址！！                                                			offset.storage.file.filename=/tmp/connect.offsets
                                               + ②连接地址
                （2）配置Source
	Source使用到的配置文件是${KAFKA_HOME}/config/connect-file-source.properties
                          【注意】修改  文件路径 和 主题名称

                （3）配置Sink
	Sink使用到的配置文件是${KAFKA_HOME}/config/connect-file-sink.properties
                          【注意】修改  文件路径 和 主题名称

                （4）启动source连接器
	  .\bin\windows\connect-standalone.bat  .\config\connect-standalone.properties  .\config\connect-file-source.properties

                （4）启动sink连接器
	  .\bin\windows\connect-standalone.bat  .\config\connect-standalone.properties  .\config\connect-file-sink.properties

十三、springboot+kafka
       基操：
          1.  导入spring-kafka依赖
          2. 配置文件：logging.level.root=info
		# 配置kafka生产者producer端口号
		spring.kafka.producer.bootstrap-servers=127.0.0.1:9092
		# 配置kafka消费者consumer端口号
		spring.kafka.consumer.bootstrap-servers=127.0.0.1:9092
		server.port=9090

          2.  自动装配 kafka模板（KafkaTemplate）  和主题
	@Autowired
    	private KafkaTemplate template;
    	private static final String topic = "csfq";
          3. 写消息生产者方法
	//消息发送者 producer
  	  @RequestMapping("/send/{input}")
   	 public  String sendToKafka(@PathVariable String input){
      	  this.template.send(topic,input);
      	  return "发送成功！消息为:"+input;
  	  }
           4. 写消息消费者
	@KafkaListener(id = "",topics = topic,groupId = "group.csfq")
  	  public void listener(String input){
      	  System.out.println("消息结果是："+input);
  	  }
         
           ！带事务版本
             1. 配置文件在上面基础上加入 
	# 事务的支持
	spring.kafka.producer.transaction-id-prefix=kafka_tx.
            
                2. 事务方法1

 	/**
     	*  事务控制，方法一:
    	 *  template.executeInTransaction
    	 * 加了事务配置才生效,spring.kafka.producer.transaction-id-prefix=kafka_tx.
     	*/
   	@RequestMapping("/transaction/{input}")
   	 public  String sendToKafka_transaction(@PathVariable String input){
       	 //加入事务的支持，共模拟二条消息
       	 template.executeInTransaction(t->{
          	  t.send(topic,input); //第一条消息
          	  if ("error".equals(input)) {//判断第一条消息
                throw new RuntimeException("input is error");
           	 }
          	  t.send(topic,input+"aaaaa");//第二条消息
          	  return true;
       	 });
       	 return "发送成功！消息为:"+input;
  	  }

               3. 事务方法二

	/**
    	 * 3.2 事务控制，方法二 (注解版本)
     	*   @Transactional(rollbackFor = RuntimeException.class)
     	*   事务配置spring.kafka.producer.transaction-id-prefix=kafka_tx.
    	 */
   	 @RequestMapping("/transaction2/{input}")
   	 @Transactional(rollbackFor = RuntimeException.class)
  	  public  String sendToKafka_transaction2(@PathVariable String input){
        	    //加入事务的支持，共模拟二条消息
           	 template.send(topic,input); //第一条消息
          	  if ("error".equals(input)) {//判断第一条消息
           	     throw new RuntimeException("input is error");
         	   }
          	  template.send(topic,input+"aaaaa");//第二条消息

       	 return "发送成功！消息为:"+input;
 	   }
          
十四、kafka集群管理
           1. zk集群
                  （1）复制两份zk，分别修改zk2 、zk3的conf\zoo.cfg 里面的clientPort=2182和		2183   （第一个zk为默认的2181）
                  （2）修改dataDir=xxdata路径xx
                  （3）修改dataLogDir=xxlog路径xx